{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal(size = 1000)\n",
    "b = np.random.normal(10,11,size = 1000)\n",
    "c = np.random.normal(12,14,size = 1000)\n",
    "d = np.random.normal(23,34,size = 1000)\n",
    "e = np.random.normal(4,5,size = 1000)\n",
    "f = np.random.normal(5,6,size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':a,\n",
    "                    'b':b,\n",
    "                    'c':c,\n",
    "                    'd':d,\n",
    "                    'e':e,\n",
    "                    'f':f,\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatePCA:\n",
    "    \"\"\"PCA algorithm using eigen vectors and eigen values\"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Principal Component Analysis is an unsupervised learning algorithm that is used \n",
    "        for the dimensionality reduction in machine learning. It is a statistical process\n",
    "        that converts the observations of correlated features into a set of linearly uncorrelated\n",
    "        features with the help of orthogonal transformation.\"\"\"\n",
    "        pass\n",
    "      \n",
    "    def __Standardize(self, df):\n",
    "        \"\"\"Standardize the columns, where variance = 1, mean = 0\"\"\"\n",
    "        for col in df.columns:\n",
    "            column = df[col]\n",
    "            colMean = column.mean()\n",
    "            n = df.shape[0]\n",
    "            stdDev = sum(((column - colMean)**2)/n)\n",
    "            df[col] = (column - colMean)/stdDev\n",
    "        return df\n",
    "        \n",
    "    def __corrMatrix(self,df):\n",
    "        \"\"\"Returns the correlation matrix for the given dataset\"\"\"\n",
    "        df = self.__Standardize(df)\n",
    "        cols = {}\n",
    "        n = df.shape[0]\n",
    "        for x in df.columns:\n",
    "            rows = []\n",
    "            xBar = df[x].mean()\n",
    "            xVal = df[x]\n",
    "            for y in df.columns:\n",
    "                yBar = df[y].mean()\n",
    "                yVal = df[y]\n",
    "                xSol = xVal - xBar\n",
    "                ySol = yVal - yBar\n",
    "                Cov = (sum(xSol.T*ySol))/n\n",
    "                rows.append(Cov)\n",
    "            cols[x] = rows\n",
    "        return pd.DataFrame(cols)\n",
    "    \n",
    "    def __returnEigens(self,df):\n",
    "        \"\"\"return the eigen values and eigen vectors for the given dataset\"\"\"\n",
    "        df = self.__corrMatrix(df)\n",
    "        eigenValue, eigenVector = np.linalg.eig(df)\n",
    "        return pd.DataFrame({\"EigenValue\":eigenValue,\n",
    "                             \"EigenVector\":list(eigenVector)\n",
    "            \n",
    "        })\n",
    "    \n",
    "    def __VarianceExplained(self, df):\n",
    "        \"\"\"This method returns a dataframe with variance explained by the eigen vectors in percentage\"\"\"\n",
    "        df = self.__returnEigens(df)\n",
    "        Variance = []\n",
    "        for i in df[\"EigenValue\"]:\n",
    "            explainedVariance = (i/sum(df[\"EigenValue\"]))*100\n",
    "            Variance.append(explainedVariance)\n",
    "        df = pd.DataFrame({\"EigenValue\":df[\"EigenValue\"].values,\n",
    "                            \"ExplainedVariance\": Variance,\n",
    "                           \"EigenVectors\": df[\"EigenVector\"]\n",
    "                            })\n",
    "        df.sort_values(by = \"ExplainedVariance\", ascending=False,inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def PCAbyVarianceExplained(self, df, varExplained = 95):\n",
    "        \"\"\"we can pass varExplained variable,\n",
    "        it will return the variance explained by n_components equal to or just next value\"\"\"\n",
    "        df = self.__VarianceExplained(df)\n",
    "        sumVariance = 0\n",
    "        flag = 0\n",
    "        for i in df[\"ExplainedVariance\"].values:\n",
    "            sumVariance += i\n",
    "            flag += 1\n",
    "            if sumVariance >= varExplained:\n",
    "                break\n",
    "        df = df[0:flag]\n",
    "        x = np.array([np.array(val) for val in df[\"EigenVectors\"].values]).T\n",
    "        print(\"The variance explained is,\",round(df[\"ExplainedVariance\"].sum(),2),\n",
    "              \"\\nComponents:\", df[\"ExplainedVariance\"].to_list())\n",
    "        return pd.DataFrame(x)\n",
    "        \n",
    "    \n",
    "    def PCAbyNComponents(self, df, n_components):\n",
    "        \"\"\"This is standard PCA like method, it will return the dataframe object with number of components passed\"\"\"\n",
    "        df = self.__VarianceExplained(df)[0:n_components]\n",
    "        x = np.array([np.array(val) for val in df[\"EigenVectors\"].values]).T\n",
    "        print(\"The variance explained is,\",round(df[\"ExplainedVariance\"].sum(),2),\n",
    "              \"\\nComponents:\", df[\"ExplainedVariance\"].to_list())\n",
    "        return pd.DataFrame(x)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"\"\"THis is a generic algorithm for PCA with some added advantage\n",
    "        1. It will show the variance explained by the number of components taken,\n",
    "        2. we can pass the value, how much variance we want to retain and it will give an dataframe object\n",
    "        of the values\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THis is a generic algorithm for PCA with some added advantage\n",
      "        1. It will show the variance explained by the number of components taken,\n",
      "        2. we can pass the value, how much variance we want to retain and it will give an dataframe object\n",
      "        of the values\n"
     ]
    }
   ],
   "source": [
    "pca = CalculatePCA()\n",
    "print(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance explained is, 98.65 \n",
      "Components: [92.35010401666058, 3.8547086505722117, 2.4454062088687225]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.999930</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>0.000126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010772</td>\n",
       "      <td>0.020039</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.001137</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>-0.012497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004608</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.072072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.010591</td>\n",
       "      <td>0.010773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000483</td>\n",
       "      <td>-0.072053</td>\n",
       "      <td>0.997258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.999930 -0.004836  0.000126\n",
       "1 -0.010772  0.020039  0.003000\n",
       "2 -0.001137 -0.003615 -0.012497\n",
       "3 -0.004608  0.997125  0.072072\n",
       "4 -0.000512 -0.010591  0.010773\n",
       "5  0.000483 -0.072053  0.997258"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.PCAbyNComponents(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([92.35010402,  3.85470865,  2.44540621])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the components with PCA from sklearn.decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform(df)\n",
    "pca.explained_variance_ratio_*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the same on a dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/dsrscientist/dataset1/master/winequality-red.csv\")\n",
    "df.drop('quality', axis = 1, inplace = True)\n",
    "df.dropna(axis=0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variance explained is, 99.98 \n",
      "Components: [99.80107167777265, 0.1565141868178203, 0.021007765250490574]\n"
     ]
    }
   ],
   "source": [
    "pca = CalculatePCA()\n",
    "newData = pca.PCAbyNComponents(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99.8011, 0.1565, 0.021]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the components with PCA from sklearn.decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit_transform(df)\n",
    "vals =[round(i, 4) for i in pca.explained_variance_ratio_*100]\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
